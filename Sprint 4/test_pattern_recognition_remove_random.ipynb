{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "The goal of Milestone 3 is to generate code to randomly remove some data to replicate incomplete data, and then determine the accuracy of the coding to determine the opening move with missing data. This code begins by randomly generating the data removed and then applying the pattern recognition framework to assess its accuracy in identifying chess openings from incomplete game records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: 'test_pattern_recognition_v2.ipynb' contains and utilises training and testing data to complete objective. This code loops around all losses and gives accuracy for all.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries and Setup\n",
    "\n",
    "This section imports the necessary libraries for data manipulation and visualisation. \n",
    "\n",
    "The sys library is used to modify the system path to include the directory where the ChessOpeningMapper module is located.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Import ChessOpeningMapper\n",
    "from ChessOpeningMapper import ChessOpeningMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\clancyam\\Documents\\GitHub\\UniSA_ICT_2024_SP4_P3_\\Sprint 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Opening Moves and Create Trie Structure.\n",
    "# \n",
    "In this step, an instance of ChessOpeningMapper is created.\n",
    "\n",
    "A list of file paths to the TSV files containing chess openings is defined.\n",
    "\n",
    "These TSV files are merged into a single DataFrame using merge_tsv_files.\n",
    "\n",
    "The PGN strings are split into individual moves using split_pgn_to_columns.\n",
    "\n",
    "A Trie structure is created from the opening moves using create_trie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Moves DataFrame:\n",
      "   eco                                     name  \\\n",
      "0  A00                             Amar Opening   \n",
      "1  A00               Amar Opening: Paris Gambit   \n",
      "2  A00  Amar Opening: Paris Gambit, Gent Gambit   \n",
      "3  A00                         Amsterdam Attack   \n",
      "4  A00                      Anderssen's Opening   \n",
      "\n",
      "                                                 pgn Move_ply_1 Move_ply_2  \\\n",
      "0                                             1. Nh3        Nh3       None   \n",
      "1                           1. Nh3 d5 2. g3 e5 3. f4        Nh3         d5   \n",
      "2  1. Nh3 d5 2. g3 e5 3. f4 Bxh3 4. Bxh3 exf4 5. ...        Nh3         d5   \n",
      "3             1. e3 e5 2. c4 d6 3. Nc3 Nc6 4. b3 Nf6         e3         e5   \n",
      "4                                              1. a3         a3       None   \n",
      "\n",
      "  Move_ply_3 Move_ply_4 Move_ply_5 Move_ply_6 Move_ply_7  ... Move_ply_28  \\\n",
      "0       None       None       None       None       None  ...        None   \n",
      "1         g3         e5         f4       None       None  ...        None   \n",
      "2         g3         e5         f4       Bxh3       Bxh3  ...        None   \n",
      "3         c4         d6        Nc3        Nc6         b3  ...        None   \n",
      "4       None       None       None       None       None  ...        None   \n",
      "\n",
      "  Move_ply_29 Move_ply_30 Move_ply_31 Move_ply_32 Move_ply_33 Move_ply_34  \\\n",
      "0        None        None        None        None        None        None   \n",
      "1        None        None        None        None        None        None   \n",
      "2        None        None        None        None        None        None   \n",
      "3        None        None        None        None        None        None   \n",
      "4        None        None        None        None        None        None   \n",
      "\n",
      "  Move_ply_35 Move_ply_36                                         plies  \n",
      "0        None        None                                           Nh3  \n",
      "1        None        None                               Nh3 d5 g3 e5 f4  \n",
      "2        None        None  Nh3 d5 g3 e5 f4 Bxh3 Bxh3 exf4 O-O fxg3 hxg3  \n",
      "3        None        None                    e3 e5 c4 d6 Nc3 Nc6 b3 Nf6  \n",
      "4        None        None                                            a3  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of ChessOpeningMapper\n",
    "mapper = ChessOpeningMapper()\n",
    "\n",
    "# Define a list of file paths to the TSV files containing chess openings, I had issues with the path, so I have mapped them manually. \n",
    "file_list = [\n",
    "    '../Chess Pattern Recognition/a.tsv',\n",
    "    '../Chess Pattern Recognition/b.tsv',\n",
    "    '../Chess Pattern Recognition/c.tsv',\n",
    "    '../Chess Pattern Recognition/d.tsv',\n",
    "    '../Chess Pattern Recognition/e.tsv'\n",
    "]\n",
    "\n",
    "# Merge the TSV files into a single DataFrame\n",
    "opening_moves = mapper.merge_tsv_files(file_list)\n",
    "\n",
    "# Split the PGN strings into individual moves\n",
    "opening_moves = mapper.split_pgn_to_columns(opening_moves)\n",
    "\n",
    "# Create a Trie structure from the opening moves\n",
    "mapper.create_trie(opening_moves)\n",
    "\n",
    "# Display the first few rows of the opening moves DataFrame\n",
    "print(\"Opening Moves DataFrame:\")\n",
    "print(opening_moves.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Unzip and Load Chess Game Data\n",
    "This step involves:\n",
    "\n",
    "Defining the path to the zipped game data file.\n",
    "\n",
    "Unzipping the game data file to extract the CSV file.\n",
    "\n",
    "Loading the extracted CSV file into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clancyam\\Documents\\GitHub\\UniSA_ICT_2024_SP4_P3_\\Sprint 4\\ChessOpeningMapper.py:152: DtypeWarning: Columns (188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  game_data = pd.read_csv(extracted_file_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Data DataFrame:\n",
      "   Index        Date  ECO                                 Opening Result  \\\n",
      "0      0  2019.04.30  B15                       Caro-Kann Defense    0-1   \n",
      "1      1  2019.04.30  C50                            Italian Game    0-1   \n",
      "2      2  2019.04.30  C41                     Philidor Defense #2    1-0   \n",
      "3      3  2019.04.30  B06                          Modern Defense    0-1   \n",
      "4      4  2019.04.30  B32  Sicilian Defense: Loewenthal Variation    1-0   \n",
      "\n",
      "  Termination TimeControl     UTCDate   UTCTime Move_ply_1  ... Clock_ply_192  \\\n",
      "0      Normal       300+3  2019.04.30  22:00:24         d4  ...           NaN   \n",
      "1      Normal       300+0  2019.04.30  22:00:13         e4  ...           NaN   \n",
      "2      Normal       600+0  2019.04.30  22:00:41         e4  ...           NaN   \n",
      "3      Normal        60+0  2019.04.30  22:00:43         e4  ...           NaN   \n",
      "4      Normal       180+0  2019.04.30  22:00:46         e4  ...           NaN   \n",
      "\n",
      "  Clock_ply_193 Clock_ply_194 Clock_ply_195 Clock_ply_196 Clock_ply_197  \\\n",
      "0           NaN           NaN           NaN           NaN           NaN   \n",
      "1           NaN           NaN           NaN           NaN           NaN   \n",
      "2           NaN           NaN           NaN           NaN           NaN   \n",
      "3           NaN           NaN           NaN           NaN           NaN   \n",
      "4           NaN           NaN           NaN           NaN           NaN   \n",
      "\n",
      "  Clock_ply_198 Clock_ply_199 Clock_ply_200 Category  \n",
      "0           NaN           NaN           NaN    Blitz  \n",
      "1           NaN           NaN           NaN    Blitz  \n",
      "2           NaN           NaN           NaN    Rapid  \n",
      "3           NaN           NaN           NaN   Bullet  \n",
      "4           NaN           NaN           NaN    Blitz  \n",
      "\n",
      "[5 rows x 410 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the zipped game data file\n",
    "game_data_zip_path = '../Chess Pattern Recognition/chessdata.zip'\n",
    "\n",
    "# Define the name of the extracted CSV file\n",
    "extracted_file_name = 'chessdata.csv'\n",
    "\n",
    "# Unzip the game data file\n",
    "ChessOpeningMapper.unzip_game_data(zip_path=game_data_zip_path, extract_to='.')\n",
    "\n",
    "# Load the extracted CSV file into a DataFrame\n",
    "game_data = ChessOpeningMapper.load_game_data(zip_path=game_data_zip_path, extracted_file_name=extracted_file_name)\n",
    "\n",
    "# Display the first few rows of the game data DataFrame\n",
    "print(\"Game Data DataFrame:\")\n",
    "print(game_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Map Opening Names to Game Data\n",
    "\n",
    "Here:\n",
    "\n",
    "The game data is processed to map the move sequences to opening names using get_opening_name_from_game.\n",
    "\n",
    "The mapped opening names are added to the original game data DataFrame in a new column called mapped_opening.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows with mapped openings: \n",
      "   Index        Date  ECO                                 Opening Result  \\\n",
      "0      0  2019.04.30  B15                       Caro-Kann Defense    0-1   \n",
      "1      1  2019.04.30  C50                            Italian Game    0-1   \n",
      "2      2  2019.04.30  C41                     Philidor Defense #2    1-0   \n",
      "3      3  2019.04.30  B06                          Modern Defense    0-1   \n",
      "4      4  2019.04.30  B32  Sicilian Defense: Loewenthal Variation    1-0   \n",
      "\n",
      "  Termination TimeControl     UTCDate   UTCTime Move_ply_1  ... Clock_ply_193  \\\n",
      "0      Normal       300+3  2019.04.30  22:00:24         d4  ...           NaN   \n",
      "1      Normal       300+0  2019.04.30  22:00:13         e4  ...           NaN   \n",
      "2      Normal       600+0  2019.04.30  22:00:41         e4  ...           NaN   \n",
      "3      Normal        60+0  2019.04.30  22:00:43         e4  ...           NaN   \n",
      "4      Normal       180+0  2019.04.30  22:00:46         e4  ...           NaN   \n",
      "\n",
      "  Clock_ply_194 Clock_ply_195 Clock_ply_196 Clock_ply_197 Clock_ply_198  \\\n",
      "0           NaN           NaN           NaN           NaN           NaN   \n",
      "1           NaN           NaN           NaN           NaN           NaN   \n",
      "2           NaN           NaN           NaN           NaN           NaN   \n",
      "3           NaN           NaN           NaN           NaN           NaN   \n",
      "4           NaN           NaN           NaN           NaN           NaN   \n",
      "\n",
      "  Clock_ply_199 Clock_ply_200 Category                         mapped_opening  \n",
      "0           NaN           NaN    Blitz  Queen's Pawn Game: Chigorin Variation  \n",
      "1           NaN           NaN    Blitz            Italian Game: Paris Defense  \n",
      "2           NaN           NaN    Rapid                       Philidor Defense  \n",
      "3           NaN           NaN   Bullet                         Modern Defense  \n",
      "4           NaN           NaN    Blitz  Sicilian Defense: Löwenthal Variation  \n",
      "\n",
      "[5 rows x 411 columns]\n"
     ]
    }
   ],
   "source": [
    "# Map the opening names to the game data\n",
    "result_df = mapper.get_opening_name_from_game(game_data)\n",
    "\n",
    "# Add the mapped opening names to the original game data DataFrame\n",
    "game_data['mapped_opening'] = result_df['opening_name']\n",
    "\n",
    "# Display the first 5 rows of the updated game data DataFrame\n",
    "print(f\"First 5 rows with mapped openings: \\n{game_data.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Train/Test Split\n",
    "\n",
    "Here: \n",
    "\n",
    "Split the dataset into training and test sets with a 70/30 ratio. Display the sizes of the train and test datasets to verify the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 139777\n",
      "Testing data size: 59905\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train/Test Split\n",
    "\n",
    "# Filter out openings that appear less than twice\n",
    "value_counts = game_data['mapped_opening'].value_counts()\n",
    "to_keep = value_counts[value_counts > 1].index\n",
    "game_data = game_data[game_data['mapped_opening'].isin(to_keep)]\n",
    "\n",
    "# Split the dataset into training and test sets (70/30) and stratify for equal representation of openings in each split\n",
    "train_df, test_df = train_test_split(game_data, test_size=0.3, random_state=42,stratify=game_data['mapped_opening'])\n",
    "\n",
    "# Display the sizes of the train and test datasets\n",
    "print(f\"Training data size: {len(train_df)}\")\n",
    "print(f\"Testing data size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Distribution:\n",
      " mapped_opening\n",
      "Queen's Pawn Game                                                 0.025491\n",
      "Horwitz Defense                                                   0.021334\n",
      "Philidor Defense                                                  0.019336\n",
      "Queen's Pawn Game: Accelerated London System                      0.018444\n",
      "Van't Kruijs Opening                                              0.016712\n",
      "                                                                    ...   \n",
      "Queen's Gambit Accepted: Alekhine Defense, Haberditz Variation    0.000010\n",
      "Borg Defense: Zilbermints Gambit                                  0.000010\n",
      "King's Gambit Accepted: Bishop's Gambit, Lopez Variation          0.000010\n",
      "Semi-Slav Defense: Marshall Gambit, Main Line                     0.000010\n",
      "English Opening: King's English Variation, Taimanov Variation     0.000010\n",
      "Name: proportion, Length: 1642, dtype: float64\n",
      "Training Distribution:\n",
      " mapped_opening\n",
      "Queen's Pawn Game                                                0.025491\n",
      "Horwitz Defense                                                  0.021334\n",
      "Philidor Defense                                                 0.019338\n",
      "Queen's Pawn Game: Accelerated London System                     0.018444\n",
      "Van't Kruijs Opening                                             0.016712\n",
      "                                                                   ...   \n",
      "Italian Game: Evans Gambit, Leonhardt Countergambit              0.000007\n",
      "Sicilian Defense: Grand Prix Attack, Schofman Variation          0.000007\n",
      "Ruy Lopez: Marshall Attack, Original Marshall Attack             0.000007\n",
      "Goldsmith Defense: Picklepuss Defense                            0.000007\n",
      "English Opening: King's English Variation, Taimanov Variation    0.000007\n",
      "Name: proportion, Length: 1642, dtype: float64\n",
      "Testing Distribution:\n",
      " mapped_opening\n",
      "Queen's Pawn Game                                                                             0.025490\n",
      "Horwitz Defense                                                                               0.021334\n",
      "Philidor Defense                                                                              0.019331\n",
      "Queen's Pawn Game: Accelerated London System                                                  0.018446\n",
      "Van't Kruijs Opening                                                                          0.016710\n",
      "                                                                                                ...   \n",
      "English Opening: King's English Variation, Four Knights Variation, Bradley Beach Variation    0.000017\n",
      "Indian Defense: Gibbins-Weidenhagen Gambit Accepted                                           0.000017\n",
      "Alekhine Defense: Four Pawns Attack, Trifunovic Variation                                     0.000017\n",
      "Benko Gambit Declined: Hjørring Countergambit                                                 0.000017\n",
      "Queen's Gambit Accepted: Mannheim Variation                                                   0.000017\n",
      "Name: proportion, Length: 1642, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Distribution:\\n\", game_data['mapped_opening'].value_counts(normalize=True))\n",
    "print(\"Training Distribution:\\n\", train_df['mapped_opening'].value_counts(normalize=True))\n",
    "print(\"Testing Distribution:\\n\", test_df['mapped_opening'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Generate Random Code\n",
    "\n",
    "Here:\n",
    "\n",
    "A method is defined to generate a random percentage of data poiints across the move plies to be removed\n",
    "\n",
    "it returns the modified dataset with the removed values and a dictionary of the lost datapoints\n",
    "\n",
    "It randomly removes data points by taking the raw data, the percentage wish to be removed and the total plies across the percentage of moves to be removed\n",
    "\n",
    "It then randomly picks a row in the dataset and a corresponding column that is the move plies within the set limit and forms the indice to be removed.\n",
    "\n",
    "The current test only works on 1% of the data across 50 plies to minimise compute time while testing.\n",
    "it the prints out the total number of row indices removed from each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of training data after random move removal:\n",
      "         Index        Date  ECO  \\\n",
      "160507  160507  2019.05.17  C45   \n",
      "156024  156024  2019.05.17  C45   \n",
      "42935    42935  2019.05.03  B12   \n",
      "29007    29007  2019.05.27  B10   \n",
      "172373  172373  2019.05.18  C55   \n",
      "\n",
      "                                                  Opening Result  \\\n",
      "160507                                        Scotch Game    0-1   \n",
      "156024                   Scotch Game: Classical Variation    0-1   \n",
      "42935   Caro-Kann Defense: Advance Variation, Short Va...    1-0   \n",
      "29007                                   Caro-Kann Defense    1-0   \n",
      "172373  Italian Game: Two Knights Defense, Max Lange A...    1-0   \n",
      "\n",
      "         Termination TimeControl     UTCDate   UTCTime Move_ply_1  ...  \\\n",
      "160507        Normal      900+15  2019.05.17  19:16:57         e4  ...   \n",
      "156024        Normal       180+0  2019.05.17   2:48:19         e4  ...   \n",
      "42935   Time forfeit       180+0  2019.05.03  23:42:29         e4  ...   \n",
      "29007         Normal      900+15  2019.05.27   0:51:54         e4  ...   \n",
      "172373  Time forfeit       300+3  2019.05.18  14:03:10         e4  ...   \n",
      "\n",
      "       Clock_ply_193 Clock_ply_194 Clock_ply_195 Clock_ply_196 Clock_ply_197  \\\n",
      "160507           NaN           NaN           NaN           NaN           NaN   \n",
      "156024           NaN           NaN           NaN           NaN           NaN   \n",
      "42935            NaN           NaN           NaN           NaN           NaN   \n",
      "29007            NaN           NaN           NaN           NaN           NaN   \n",
      "172373           NaN           NaN           NaN           NaN           NaN   \n",
      "\n",
      "       Clock_ply_198 Clock_ply_199 Clock_ply_200   Category  \\\n",
      "160507           NaN           NaN           NaN  Classical   \n",
      "156024           NaN           NaN           NaN      Blitz   \n",
      "42935            NaN           NaN           NaN      Blitz   \n",
      "29007            NaN           NaN           NaN  Classical   \n",
      "172373           NaN           NaN           NaN      Blitz   \n",
      "\n",
      "                                           mapped_opening  \n",
      "160507                                        Scotch Game  \n",
      "156024                   Scotch Game: Classical Variation  \n",
      "42935   Caro-Kann Defense: Advance Variation, Short Va...  \n",
      "29007                                   Caro-Kann Defense  \n",
      "172373                         Italian Game: Deutz Gambit  \n",
      "\n",
      "[5 rows x 411 columns]\n",
      "Sample of testing data after random move removal:\n",
      "         Index        Date  ECO  \\\n",
      "76403    76403  2019.05.01  C62   \n",
      "48651    48651  2019.05.28  D31   \n",
      "100696  100696  2019.05.08  C15   \n",
      "2971      2971  2019.05.22  E10   \n",
      "110570  110570  2019.05.09  C00   \n",
      "\n",
      "                                                  Opening Result  \\\n",
      "76403                         Ruy Lopez: Steinitz Defense    0-1   \n",
      "48651   Queen's Gambit Declined: Queen's Knight Variation    0-1   \n",
      "100696                  French Defense: Winawer Variation    1-0   \n",
      "2971                       Indian Game: Anti-Nimzo-Indian    1-0   \n",
      "110570                   French Defense: Knight Variation    1-0   \n",
      "\n",
      "         Termination TimeControl     UTCDate   UTCTime Move_ply_1  ...  \\\n",
      "76403   Time forfeit       180+2  2019.05.01  16:39:19         e4  ...   \n",
      "48651   Time forfeit       180+0  2019.05.28  21:49:23         c4  ...   \n",
      "100696        Normal      900+15  2019.05.08  13:52:10         e4  ...   \n",
      "2971          Normal       180+2  2019.05.22  22:20:22         d4  ...   \n",
      "110570  Time forfeit      180+15  2019.05.09  23:53:25         e4  ...   \n",
      "\n",
      "       Clock_ply_193 Clock_ply_194 Clock_ply_195 Clock_ply_196 Clock_ply_197  \\\n",
      "76403            NaN           NaN           NaN           NaN           NaN   \n",
      "48651            NaN           NaN           NaN           NaN           NaN   \n",
      "100696           NaN           NaN           NaN           NaN           NaN   \n",
      "2971             NaN           NaN           NaN           NaN           NaN   \n",
      "110570           NaN           NaN           NaN           NaN           NaN   \n",
      "\n",
      "       Clock_ply_198 Clock_ply_199 Clock_ply_200   Category  \\\n",
      "76403            NaN           NaN           NaN      Blitz   \n",
      "48651            NaN           NaN           NaN      Blitz   \n",
      "100696           NaN           NaN           NaN  Classical   \n",
      "2971             NaN           NaN           NaN      Blitz   \n",
      "110570           NaN           NaN           NaN      Rapid   \n",
      "\n",
      "                            mapped_opening  \n",
      "76403          Ruy Lopez: Steinitz Defense  \n",
      "48651   English Opening: Agincourt Defense  \n",
      "100696   French Defense: Winawer Variation  \n",
      "2971     Indian Defense: Anti-Nimzo-Indian  \n",
      "110570    French Defense: Knight Variation  \n",
      "\n",
      "[5 rows x 411 columns]\n",
      "Column 50: 1370 rows removed\n",
      "Column 70: 1400 rows removed\n",
      "Column 26: 1372 rows removed\n",
      "Column 17: 1359 rows removed\n",
      "Column 29: 1409 rows removed\n",
      "Column 78: 1436 rows removed\n",
      "Column 33: 1409 rows removed\n",
      "Column 91: 1346 rows removed\n",
      "Column 28: 1447 rows removed\n",
      "Column 84: 1360 rows removed\n",
      "Column 19: 1407 rows removed\n",
      "Column 6: 1330 rows removed\n",
      "Column 57: 1355 rows removed\n",
      "Column 44: 1375 rows removed\n",
      "Column 92: 1328 rows removed\n",
      "Column 58: 1425 rows removed\n",
      "Column 8: 1421 rows removed\n",
      "Column 95: 1461 rows removed\n",
      "Column 16: 1424 rows removed\n",
      "Column 77: 1422 rows removed\n",
      "Column 65: 1454 rows removed\n",
      "Column 27: 1391 rows removed\n",
      "Column 54: 1357 rows removed\n",
      "Column 23: 1418 rows removed\n",
      "Column 46: 1391 rows removed\n",
      "Column 37: 1359 rows removed\n",
      "Column 22: 1405 rows removed\n",
      "Column 31: 1386 rows removed\n",
      "Column 80: 1332 rows removed\n",
      "Column 18: 1386 rows removed\n",
      "Column 99: 1421 rows removed\n",
      "Column 21: 1388 rows removed\n",
      "Column 96: 1443 rows removed\n",
      "Column 97: 1416 rows removed\n",
      "Column 76: 1366 rows removed\n",
      "Column 51: 1398 rows removed\n",
      "Column 38: 1394 rows removed\n",
      "Column 25: 1387 rows removed\n",
      "Column 5: 1379 rows removed\n",
      "Column 0: 1425 rows removed\n",
      "Column 47: 1454 rows removed\n",
      "Column 20: 1368 rows removed\n",
      "Column 59: 1405 rows removed\n",
      "Column 52: 1474 rows removed\n",
      "Column 35: 1332 rows removed\n",
      "Column 3: 1346 rows removed\n",
      "Column 82: 1408 rows removed\n",
      "Column 64: 1424 rows removed\n",
      "Column 10: 1454 rows removed\n",
      "Column 67: 1415 rows removed\n",
      "Column 4: 1398 rows removed\n",
      "Column 32: 1429 rows removed\n",
      "Column 60: 1325 rows removed\n",
      "Column 45: 1377 rows removed\n",
      "Column 30: 1370 rows removed\n",
      "Column 81: 1449 rows removed\n",
      "Column 93: 1328 rows removed\n",
      "Column 14: 1403 rows removed\n",
      "Column 88: 1452 rows removed\n",
      "Column 15: 1405 rows removed\n",
      "Column 61: 1395 rows removed\n",
      "Column 86: 1423 rows removed\n",
      "Column 85: 1413 rows removed\n",
      "Column 49: 1467 rows removed\n",
      "Column 98: 1387 rows removed\n",
      "Column 2: 1375 rows removed\n",
      "Column 56: 1380 rows removed\n",
      "Column 40: 1385 rows removed\n",
      "Column 94: 1447 rows removed\n",
      "Column 71: 1483 rows removed\n",
      "Column 39: 1416 rows removed\n",
      "Column 24: 1410 rows removed\n",
      "Column 43: 1426 rows removed\n",
      "Column 87: 1437 rows removed\n",
      "Column 73: 1381 rows removed\n",
      "Column 62: 1361 rows removed\n",
      "Column 75: 1414 rows removed\n",
      "Column 55: 1401 rows removed\n",
      "Column 63: 1444 rows removed\n",
      "Column 48: 1393 rows removed\n",
      "Column 34: 1373 rows removed\n",
      "Column 68: 1384 rows removed\n",
      "Column 41: 1425 rows removed\n",
      "Column 74: 1365 rows removed\n",
      "Column 72: 1409 rows removed\n",
      "Column 12: 1364 rows removed\n",
      "Column 11: 1457 rows removed\n",
      "Column 1: 1350 rows removed\n",
      "Column 69: 1414 rows removed\n",
      "Column 13: 1355 rows removed\n",
      "Column 89: 1409 rows removed\n",
      "Column 90: 1343 rows removed\n",
      "Column 66: 1396 rows removed\n",
      "Column 9: 1396 rows removed\n",
      "Column 36: 1369 rows removed\n",
      "Column 42: 1358 rows removed\n",
      "Column 79: 1413 rows removed\n",
      "Column 7: 1408 rows removed\n",
      "Column 83: 1438 rows removed\n",
      "Column 53: 1345 rows removed\n"
     ]
    }
   ],
   "source": [
    "# Generate Random Code and Apply to Both Datasets\n",
    "def generate_random_data_removal(data, percent_remove=5, total_plies=100):\n",
    "    \"\"\"\n",
    "    Randomly removes a specified percentage of data points from the first 'total_plies' columns of a DataFrame,\n",
    "    and returns a dictionary of the indices removed.\n",
    "\n",
    "    Args:\n",
    "    - data (pd.DataFrame): The DataFrame from which to remove data.\n",
    "    - percent_remove (int): The percentage of data points to remove.\n",
    "    - total_plies (int): The total number of plies to consider for data removal.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with randomly removed data points.\n",
    "    - dict: A dictionary containing the indices of the data points that were removed.\n",
    "    \"\"\"\n",
    "    modified_data = data.copy()\n",
    "    loss_dict = {}\n",
    "\n",
    "    # Calculate the total number of data points to remove\n",
    "    num_data_points = int((total_plies * len(data)) * (percent_remove / 100))\n",
    "    \n",
    "    # Generate random row and column indices to set to None\n",
    "    row_indices = np.random.randint(0, len(data), num_data_points)\n",
    "    col_indices = np.random.randint(0, total_plies, num_data_points)  \n",
    "    \n",
    "    # Set the selected data points to None and record the indices in loss_dict\n",
    "    for row, col in zip(row_indices, col_indices):\n",
    "        modified_data.iloc[row, col] = None\n",
    "        if col in loss_dict:\n",
    "            loss_dict[col].append(row)\n",
    "        else:\n",
    "            loss_dict[col] = [row]\n",
    "\n",
    "\n",
    "\n",
    "    return modified_data, loss_dict\n",
    "\n",
    "\n",
    "\n",
    "# Apply random move removal to training and testing datasets for all losses\n",
    "train_datasets, train_loss_dict = generate_random_data_removal(train_df,percent_remove=1,total_plies = 100)\n",
    "test_datasets, test_loss_dict = generate_random_data_removal(test_df,percent_remove=1, total_plies=100)\n",
    "\n",
    "print(\"Sample of training data after random move removal:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"Sample of testing data after random move removal:\")\n",
    "print(test_df.head())\n",
    "\n",
    "# test example of 1% of data removed across 50 plies of the training data\n",
    "for column, rows in train_loss_dict.items():\n",
    "    print(f\"Column {column}: {len(rows)} rows removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6.1 Testing**\n",
    "This tests that the data that has been removed is exclusivly from the plies columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original values removed from Column Move_ply_51:\n",
      "106269     Qh4\n",
      "109039     Nf5\n",
      "78860      NaN\n",
      "9905       NaN\n",
      "52782     Nxe5\n",
      "99548      NaN\n",
      "124209     NaN\n",
      "73723      NaN\n",
      "110753    Rxf1\n",
      "43725      NaN\n",
      "47855      Qc3\n",
      "4926      dxe5\n",
      "93795      Qh6\n",
      "53368       g4\n",
      "113230     Nh4\n",
      "95548     Rhg1\n",
      "57368      NaN\n",
      "76746     Bxh3\n",
      "109425     Kg2\n",
      "102291    gxf4\n",
      "Name: Move_ply_51, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def print_removed_values(data, loss_dict, max_samples=20):\n",
    "    total_displayed = 0  # Counter to track how many values have been displayed\n",
    "\n",
    "    for column, rows in loss_dict.items():\n",
    "        column_name = f'Move_ply_{column+1}'  \n",
    "        if len(rows) > 0:\n",
    "            original_values = data.loc[rows, column_name]  \n",
    "            sample_size = min(len(rows), max_samples - total_displayed)  \n",
    "            print(f\"Original values removed from Column {column_name}:\")\n",
    "            print(original_values.sample(sample_size))  \n",
    "\n",
    "            total_displayed += sample_size  # Update the counter\n",
    "            if total_displayed >= max_samples:\n",
    "                break  # Stop if the maximum number of samples has been reached\n",
    "\n",
    "#Resets the index of the game data dataframe\n",
    "game_data.reset_index(drop=True, inplace=True)\n",
    "# Example usage\n",
    "print_removed_values(game_data, train_loss_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Prepare Data for Testing\n",
    "\n",
    "In this step, game data is processed to create sequences from non-null moves, preparing it for pattern recognition testing. This step ensures each game's moves are consolidated into a format suitable for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data by creating move sequences from non-null moves\n",
    "def prepare_game_data_for_testing(game_data, max_plies=200):\n",
    "    \n",
    "    \"\"\"\n",
    "    Prepare the game data by creating move sequences from non-null moves.\n",
    "    \n",
    "    Args:\n",
    "    - game_data (pd.DataFrame): The DataFrame with chess moves.\n",
    "    - max_plies (int): The maximum number of plies to consider (default is 200).\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with a new column 'move_sequence' containing sequences of moves.\n",
    "    \"\"\"\n",
    "    \n",
    "    move_columns = [f'Move_ply_{i+1}' for i in range(max_plies)]\n",
    "    selected_moves_df = game_data[move_columns].copy()\n",
    "\n",
    "    def create_move_sequence(row):\n",
    "        moves = row.dropna().tolist()  # Drop NaN values and convert to list\n",
    "        return ' '.join(moves)\n",
    "\n",
    "    selected_moves_df['move_sequence'] = selected_moves_df.apply(create_move_sequence, axis=1)\n",
    "    selected_moves_df['mapped_opening'] = game_data['mapped_opening']  \n",
    "    return selected_moves_df\n",
    "\n",
    "# Prepare the incomplete game data for testing\n",
    "# For simplicity, let's use the first modified dataset for further processing\n",
    "processed_train_data_sample = prepare_game_data_for_testing(train_datasets)\n",
    "processed_test_data_sample = prepare_game_data_for_testing(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Move_ply_1</th>\n",
       "      <th>Move_ply_2</th>\n",
       "      <th>Move_ply_3</th>\n",
       "      <th>Move_ply_4</th>\n",
       "      <th>Move_ply_5</th>\n",
       "      <th>Move_ply_6</th>\n",
       "      <th>Move_ply_7</th>\n",
       "      <th>Move_ply_8</th>\n",
       "      <th>Move_ply_9</th>\n",
       "      <th>Move_ply_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Move_ply_193</th>\n",
       "      <th>Move_ply_194</th>\n",
       "      <th>Move_ply_195</th>\n",
       "      <th>Move_ply_196</th>\n",
       "      <th>Move_ply_197</th>\n",
       "      <th>Move_ply_198</th>\n",
       "      <th>Move_ply_199</th>\n",
       "      <th>Move_ply_200</th>\n",
       "      <th>move_sequence</th>\n",
       "      <th>mapped_opening</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76403</th>\n",
       "      <td>e4</td>\n",
       "      <td>e5</td>\n",
       "      <td>Nf3</td>\n",
       "      <td>Nc6</td>\n",
       "      <td>Bb5</td>\n",
       "      <td>d6</td>\n",
       "      <td>Bxc6+</td>\n",
       "      <td>bxc6</td>\n",
       "      <td>d4</td>\n",
       "      <td>exd4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e4 e5 Nf3 Nc6 Bb5 d6 Bxc6+ bxc6 d4 exd4 Nxd4 N...</td>\n",
       "      <td>Ruy Lopez: Steinitz Defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48651</th>\n",
       "      <td>c4</td>\n",
       "      <td>e6</td>\n",
       "      <td>Nc3</td>\n",
       "      <td>d5</td>\n",
       "      <td>d4</td>\n",
       "      <td>dxc4</td>\n",
       "      <td>e4</td>\n",
       "      <td>Nf6</td>\n",
       "      <td>Bxc4</td>\n",
       "      <td>c5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c4 e6 Nc3 d5 d4 dxc4 e4 Nf6 Bxc4 c5 d5 exd5 ex...</td>\n",
       "      <td>English Opening: Agincourt Defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100696</th>\n",
       "      <td>e4</td>\n",
       "      <td>e6</td>\n",
       "      <td>d4</td>\n",
       "      <td>d5</td>\n",
       "      <td>Nc3</td>\n",
       "      <td>Bb4</td>\n",
       "      <td>Bd3</td>\n",
       "      <td>Nf6</td>\n",
       "      <td>e5</td>\n",
       "      <td>Nfd7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e4 e6 d4 d5 Nc3 Bb4 Bd3 Nf6 e5 Nfd7 Qg4 O-O Bh...</td>\n",
       "      <td>French Defense: Winawer Variation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>d4</td>\n",
       "      <td>Nf6</td>\n",
       "      <td>c4</td>\n",
       "      <td>e6</td>\n",
       "      <td>Nf3</td>\n",
       "      <td>d5</td>\n",
       "      <td>cxd5</td>\n",
       "      <td>exd5</td>\n",
       "      <td>Bg5</td>\n",
       "      <td>c6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d4 Nf6 c4 e6 Nf3 d5 cxd5 exd5 Bg5 c6 e3 Bd6 Nc...</td>\n",
       "      <td>Indian Defense: Anti-Nimzo-Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110570</th>\n",
       "      <td>e4</td>\n",
       "      <td>e6</td>\n",
       "      <td>Nf3</td>\n",
       "      <td>b6</td>\n",
       "      <td>d4</td>\n",
       "      <td>Bb7</td>\n",
       "      <td>Bd3</td>\n",
       "      <td>f5</td>\n",
       "      <td>Qe2</td>\n",
       "      <td>Nf6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e4 e6 Nf3 b6 d4 Bb7 Bd3 f5 Qe2 Nf6 exf5 Bd6 fx...</td>\n",
       "      <td>French Defense: Knight Variation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Move_ply_1 Move_ply_2 Move_ply_3 Move_ply_4 Move_ply_5 Move_ply_6  \\\n",
       "76403          e4         e5        Nf3        Nc6        Bb5         d6   \n",
       "48651          c4         e6        Nc3         d5         d4       dxc4   \n",
       "100696         e4         e6         d4         d5        Nc3        Bb4   \n",
       "2971           d4        Nf6         c4         e6        Nf3         d5   \n",
       "110570         e4         e6        Nf3         b6         d4        Bb7   \n",
       "\n",
       "       Move_ply_7 Move_ply_8 Move_ply_9 Move_ply_10  ... Move_ply_193  \\\n",
       "76403       Bxc6+       bxc6         d4        exd4  ...          NaN   \n",
       "48651          e4        Nf6       Bxc4          c5  ...          NaN   \n",
       "100696        Bd3        Nf6         e5        Nfd7  ...          NaN   \n",
       "2971         cxd5       exd5        Bg5          c6  ...          NaN   \n",
       "110570        Bd3         f5        Qe2         Nf6  ...          NaN   \n",
       "\n",
       "       Move_ply_194 Move_ply_195 Move_ply_196 Move_ply_197 Move_ply_198  \\\n",
       "76403           NaN          NaN          NaN          NaN          NaN   \n",
       "48651           NaN          NaN          NaN          NaN          NaN   \n",
       "100696          NaN          NaN          NaN          NaN          NaN   \n",
       "2971            NaN          NaN          NaN          NaN          NaN   \n",
       "110570          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "       Move_ply_199 Move_ply_200  \\\n",
       "76403           NaN          NaN   \n",
       "48651           NaN          NaN   \n",
       "100696          NaN          NaN   \n",
       "2971            NaN          NaN   \n",
       "110570          NaN          NaN   \n",
       "\n",
       "                                            move_sequence  \\\n",
       "76403   e4 e5 Nf3 Nc6 Bb5 d6 Bxc6+ bxc6 d4 exd4 Nxd4 N...   \n",
       "48651   c4 e6 Nc3 d5 d4 dxc4 e4 Nf6 Bxc4 c5 d5 exd5 ex...   \n",
       "100696  e4 e6 d4 d5 Nc3 Bb4 Bd3 Nf6 e5 Nfd7 Qg4 O-O Bh...   \n",
       "2971    d4 Nf6 c4 e6 Nf3 d5 cxd5 exd5 Bg5 c6 e3 Bd6 Nc...   \n",
       "110570  e4 e6 Nf3 b6 d4 Bb7 Bd3 f5 Qe2 Nf6 exf5 Bd6 fx...   \n",
       "\n",
       "                            mapped_opening  \n",
       "76403          Ruy Lopez: Steinitz Defense  \n",
       "48651   English Opening: Agincourt Defense  \n",
       "100696   French Defense: Winawer Variation  \n",
       "2971     Indian Defense: Anti-Nimzo-Indian  \n",
       "110570    French Defense: Knight Variation  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test_data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Test Pattern Recognition on Incomplete Data\n",
    "\n",
    "In this step, the ChessOpeningMapper is used to predict chess openings from the processed, incomplete data. The predicted openings are then compared with the actual mapped openings to determine the accuracy of the model, assessing its ability to handle missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on incomplete training data: 96.10%\n",
      "Accuracy on incomplete testing data: 95.99%\n"
     ]
    }
   ],
   "source": [
    "# Test pattern recognition on incomplete data\n",
    "def test_pattern_recognition_on_incomplete_data(mapper, incomplete_df, dataset_label):\n",
    "    \n",
    "    \"\"\"\n",
    "    Test the pattern recognition on incomplete data using ChessOpeningMapper.\n",
    "    \n",
    "    Args:\n",
    "    - mapper (ChessOpeningMapper): The ChessOpeningMapper instance for mapping openings.\n",
    "    - incomplete_df (pd.DataFrame): The DataFrame containing incomplete chess move data.\n",
    "    - dataset_label (str): Label to indicate which dataset is being tested (e.g., 'Training' or 'Testing').\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with the original and predicted openings for comparison.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use the mapper to predict openings based on incomplete data\n",
    "    incomplete_results = mapper.get_opening_name_from_game(incomplete_df)\n",
    "    incomplete_df['predicted_opening'] = incomplete_results['opening_name']\n",
    "    \n",
    "    if 'mapped_opening' in incomplete_df.columns:\n",
    "        incomplete_df['match'] = incomplete_df['mapped_opening'] == incomplete_df['predicted_opening']\n",
    "        accuracy = incomplete_df['match'].mean()\n",
    "        print(f'Accuracy on incomplete {dataset_label} data: {accuracy:.2%}')\n",
    "    else:\n",
    "        print(f\"No 'mapped_opening' column found in input {dataset_label} data\")\n",
    "    \n",
    "    return incomplete_df\n",
    "\n",
    "# Instantiate ChessOpeningMapper and load trie\n",
    "mapper = ChessOpeningMapper()\n",
    "opening_moves = mapper.load_openings()\n",
    "mapper.create_trie(opening_moves)\n",
    "\n",
    "# Run the test on both training and testing data\n",
    "train_result_df_test = test_pattern_recognition_on_incomplete_data(mapper, processed_train_data_sample, \"training\")\n",
    "test_result_df_test = test_pattern_recognition_on_incomplete_data(mapper, processed_test_data_sample, \"testing\")\n",
    "\n",
    "\n",
    "# Print results for training data\n",
    "#print(\"\\nTraining Data Results:\")\n",
    "#print(\"-\" * 50)\n",
    "#if 'mapped_opening' in train_result_df.columns and 'match' in train_result_df.columns:\n",
    " #   print(train_result_df[['mapped_opening', 'predicted_opening', 'match']].head())\n",
    "#else:\n",
    "#    print(\"Mapped or Match columns not found in the train result DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on incomplete training (50) data: 92.32%\n",
      "Accuracy on incomplete testing (50) data: 92.27%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loss_key \u001b[38;5;129;01min\u001b[39;00m train_loss_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m      7\u001b[0m     \n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Unpack the tuple returned by generate_random_data_removal\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     modified_train_data, _ \u001b[38;5;241m=\u001b[39m generate_random_data_removal(train_datasets, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Assuming 1 is the loss percentage\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     modified_test_data, _ \u001b[38;5;241m=\u001b[39m generate_random_data_removal(test_datasets, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Proceed with data processing\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 28\u001b[0m, in \u001b[0;36mgenerate_random_data_removal\u001b[1;34m(data, percent_remove, total_plies)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Set the selected data points to None and record the indices in loss_dict\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(row_indices, col_indices):\n\u001b[1;32m---> 28\u001b[0m     modified_data\u001b[38;5;241m.\u001b[39miloc[row, col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m loss_dict:\n\u001b[0;32m     30\u001b[0m         loss_dict[col]\u001b[38;5;241m.\u001b[39mappend(row)\n",
      "File \u001b[1;32mc:\\Users\\clancyam\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:885\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    884\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 885\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\clancyam\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1893\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1892\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1894\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\clancyam\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1986\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1983\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1984\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loc \u001b[38;5;129;01min\u001b[39;00m ilocs:\n\u001b[1;32m-> 1986\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_column(loc, value, pi)\n",
      "File \u001b[1;32mc:\\Users\\clancyam\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:2095\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_column\u001b[1;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[0;32m   2091\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39misetitem(loc, value)\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2093\u001b[0m     \u001b[38;5;66;03m# set value into the column (first attempting to operate inplace, then\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m     \u001b[38;5;66;03m#  falling back to casting if necessary)\u001b[39;00m\n\u001b[1;32m-> 2095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mcolumn_setitem(loc, plane_indexer, value)\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\clancyam\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1309\u001b[0m, in \u001b[0;36mBlockManager.column_setitem\u001b[1;34m(self, loc, idx, value, inplace_only)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1308\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m col_mgr\u001b[38;5;241m.\u001b[39msetitem((idx,), value)\n\u001b[1;32m-> 1309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miset(loc, new_mgr\u001b[38;5;241m.\u001b[39m_block\u001b[38;5;241m.\u001b[39mvalues, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\clancyam\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1128\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[1;34m(self, loc, value, inplace, refs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1127\u001b[0m         blk\u001b[38;5;241m.\u001b[39mset_inplace(blk_locs, value_getitem(val_locs))\n\u001b[1;32m-> 1128\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1130\u001b[0m     unfit_mgr_locs\u001b[38;5;241m.\u001b[39mappend(blk\u001b[38;5;241m.\u001b[39mmgr_locs\u001b[38;5;241m.\u001b[39mas_array[blk_locs])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Test pattern recognition on all losses for both train and test datasets\n",
    "\n",
    "### Note this will take a long time as it calculates the lost for 1% of data across 50 plies, suggest just running for 10 minutes\n",
    "### or so just to get an idea that the ouput is working.\n",
    "results = {}\n",
    "for loss_key in train_loss_dict.keys():\n",
    "    \n",
    "\n",
    "    # Unpack the tuple returned by generate_random_data_removal\n",
    "    modified_train_data, _ = generate_random_data_removal(train_datasets, 1)  # Assuming 1 is the loss percentage\n",
    "    modified_test_data, _ = generate_random_data_removal(test_datasets, 1)\n",
    "\n",
    "    # Proceed with data processing\n",
    "    processed_train_data = prepare_game_data_for_testing(modified_train_data)\n",
    "    processed_test_data = prepare_game_data_for_testing(modified_test_data)\n",
    "\n",
    "    # Pattern recognition and results storage\n",
    "    train_result_df = test_pattern_recognition_on_incomplete_data(mapper, processed_train_data, f\"training ({loss_key})\")\n",
    "    test_result_df = test_pattern_recognition_on_incomplete_data(mapper, processed_test_data, f\"testing ({loss_key})\")\n",
    "\n",
    "    results[loss_key] = {\n",
    "        'train': train_result_df,\n",
    "        'test': test_result_df\n",
    "     }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
