{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "The goal of Milestone 3 is to generate code to randomly remove some data to replicate incomplete data, and then determine the accuracy of the coding to determine the opening move with missing data. This code begins by randomly generating the data removed and then applying the pattern recognition framework to assess its accuracy in identifying chess openings from incomplete game records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: 'test_pattern_recognition_v2.ipynb' contains and utilises training and testing data to complete objective. This code loops around all losses and gives accuracy for all.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries and Setup\n",
    "\n",
    "This section imports the necessary libraries for data manipulation and visualisation. \n",
    "\n",
    "The sys library is used to modify the system path to include the directory where the ChessOpeningMapper module is located.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add the path to the directory where ChessOpeningMapper.py is located. I had issues with the path, \n",
    "# so I went with the relative path. This will have to change.\n",
    "sys.path.append(r'Sprint 2')\n",
    "\n",
    "# Import ChessOpeningMapper\n",
    "from ChessOpeningMapper import ChessOpeningMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\jenni\\Desktop\\jn\\uni\\capstone 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Opening Moves and Create Trie Structure.\n",
    "# \n",
    "In this step, an instance of ChessOpeningMapper is created.\n",
    "\n",
    "A list of file paths to the TSV files containing chess openings is defined.\n",
    "\n",
    "These TSV files are merged into a single DataFrame using merge_tsv_files.\n",
    "\n",
    "The PGN strings are split into individual moves using split_pgn_to_columns.\n",
    "\n",
    "A Trie structure is created from the opening moves using create_trie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Moves DataFrame:\n",
      "   eco                                     name  \\\n",
      "0  A00                             Amar Opening   \n",
      "1  A00               Amar Opening: Paris Gambit   \n",
      "2  A00  Amar Opening: Paris Gambit, Gent Gambit   \n",
      "3  A00                         Amsterdam Attack   \n",
      "4  A00                      Anderssen's Opening   \n",
      "\n",
      "                                                 pgn Move_ply_1 Move_ply_2  \\\n",
      "0                                             1. Nh3        Nh3       None   \n",
      "1                           1. Nh3 d5 2. g3 e5 3. f4        Nh3         d5   \n",
      "2  1. Nh3 d5 2. g3 e5 3. f4 Bxh3 4. Bxh3 exf4 5. ...        Nh3         d5   \n",
      "3             1. e3 e5 2. c4 d6 3. Nc3 Nc6 4. b3 Nf6         e3         e5   \n",
      "4                                              1. a3         a3       None   \n",
      "\n",
      "  Move_ply_3 Move_ply_4 Move_ply_5 Move_ply_6 Move_ply_7  ... Move_ply_28  \\\n",
      "0       None       None       None       None       None  ...        None   \n",
      "1         g3         e5         f4       None       None  ...        None   \n",
      "2         g3         e5         f4       Bxh3       Bxh3  ...        None   \n",
      "3         c4         d6        Nc3        Nc6         b3  ...        None   \n",
      "4       None       None       None       None       None  ...        None   \n",
      "\n",
      "  Move_ply_29 Move_ply_30 Move_ply_31 Move_ply_32 Move_ply_33 Move_ply_34  \\\n",
      "0        None        None        None        None        None        None   \n",
      "1        None        None        None        None        None        None   \n",
      "2        None        None        None        None        None        None   \n",
      "3        None        None        None        None        None        None   \n",
      "4        None        None        None        None        None        None   \n",
      "\n",
      "  Move_ply_35 Move_ply_36                                         plies  \n",
      "0        None        None                                           Nh3  \n",
      "1        None        None                               Nh3 d5 g3 e5 f4  \n",
      "2        None        None  Nh3 d5 g3 e5 f4 Bxh3 Bxh3 exf4 O-O fxg3 hxg3  \n",
      "3        None        None                    e3 e5 c4 d6 Nc3 Nc6 b3 Nf6  \n",
      "4        None        None                                            a3  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of ChessOpeningMapper\n",
    "mapper = ChessOpeningMapper()\n",
    "\n",
    "# Define a list of file paths to the TSV files containing chess openings, I had issues with the path, so I have mapped them manually. \n",
    "file_list = [\n",
    "    r'Chess Pattern Recognition\\a.tsv',\n",
    "    r'Chess Pattern Recognition\\b.tsv',\n",
    "    r'Chess Pattern Recognition\\c.tsv',\n",
    "    r'Chess Pattern Recognition\\d.tsv',\n",
    "    r'Chess Pattern Recognition\\e.tsv'\n",
    "]\n",
    "\n",
    "# Merge the TSV files into a single DataFrame\n",
    "opening_moves = mapper.merge_tsv_files(file_list)\n",
    "\n",
    "# Split the PGN strings into individual moves\n",
    "opening_moves = mapper.split_pgn_to_columns(opening_moves)\n",
    "\n",
    "# Create a Trie structure from the opening moves\n",
    "mapper.create_trie(opening_moves)\n",
    "\n",
    "# Display the first few rows of the opening moves DataFrame\n",
    "print(\"Opening Moves DataFrame:\")\n",
    "print(opening_moves.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Unzip and Load Chess Game Data\n",
    "This step involves:\n",
    "\n",
    "Defining the path to the zipped game data file.\n",
    "\n",
    "Unzipping the game data file to extract the CSV file.\n",
    "\n",
    "Loading the extracted CSV file into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jenni\\Desktop\\jn\\uni\\capstone 1\\Sprint 2\\ChessOpeningMapper.py:104: DtypeWarning: Columns (188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  game_data = pd.read_csv(extracted_file_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Data DataFrame:\n",
      "   Index        Date  ECO                                 Opening Result  \\\n",
      "0      0  2019.04.30  B15                       Caro-Kann Defense    0-1   \n",
      "1      1  2019.04.30  C50                            Italian Game    0-1   \n",
      "2      2  2019.04.30  C41                     Philidor Defense #2    1-0   \n",
      "3      3  2019.04.30  B06                          Modern Defense    0-1   \n",
      "4      4  2019.04.30  B32  Sicilian Defense: Loewenthal Variation    1-0   \n",
      "\n",
      "  Termination TimeControl     UTCDate   UTCTime Move_ply_1  ... Clock_ply_192  \\\n",
      "0      Normal       300+3  2019.04.30  22:00:24         d4  ...           NaN   \n",
      "1      Normal       300+0  2019.04.30  22:00:13         e4  ...           NaN   \n",
      "2      Normal       600+0  2019.04.30  22:00:41         e4  ...           NaN   \n",
      "3      Normal        60+0  2019.04.30  22:00:43         e4  ...           NaN   \n",
      "4      Normal       180+0  2019.04.30  22:00:46         e4  ...           NaN   \n",
      "\n",
      "  Clock_ply_193 Clock_ply_194 Clock_ply_195 Clock_ply_196 Clock_ply_197  \\\n",
      "0           NaN           NaN           NaN           NaN           NaN   \n",
      "1           NaN           NaN           NaN           NaN           NaN   \n",
      "2           NaN           NaN           NaN           NaN           NaN   \n",
      "3           NaN           NaN           NaN           NaN           NaN   \n",
      "4           NaN           NaN           NaN           NaN           NaN   \n",
      "\n",
      "  Clock_ply_198 Clock_ply_199 Clock_ply_200 Category  \n",
      "0           NaN           NaN           NaN    Blitz  \n",
      "1           NaN           NaN           NaN    Blitz  \n",
      "2           NaN           NaN           NaN    Rapid  \n",
      "3           NaN           NaN           NaN   Bullet  \n",
      "4           NaN           NaN           NaN    Blitz  \n",
      "\n",
      "[5 rows x 410 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the zipped game data file\n",
    "game_data_zip_path = r'Chess Pattern Recognition\\chessdata.zip'\n",
    "\n",
    "# Define the name of the extracted CSV file\n",
    "extracted_file_name = 'chessdata.csv'\n",
    "\n",
    "# Unzip the game data file\n",
    "ChessOpeningMapper.unzip_game_data(zip_path=game_data_zip_path, extract_to='.')\n",
    "\n",
    "# Load the extracted CSV file into a DataFrame\n",
    "game_data = ChessOpeningMapper.load_game_data(zip_path=game_data_zip_path, extracted_file_name=extracted_file_name)\n",
    "\n",
    "# Display the first few rows of the game data DataFrame\n",
    "print(\"Game Data DataFrame:\")\n",
    "print(game_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Map Opening Names to Game Data\n",
    "\n",
    "Here:\n",
    "\n",
    "The game data is processed to map the move sequences to opening names using get_opening_name_from_game.\n",
    "\n",
    "The mapped opening names are added to the original game data DataFrame in a new column called mapped_opening.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows with mapped openings: \n",
      "   Index        Date  ECO                                 Opening Result  \\\n",
      "0      0  2019.04.30  B15                       Caro-Kann Defense    0-1   \n",
      "1      1  2019.04.30  C50                            Italian Game    0-1   \n",
      "2      2  2019.04.30  C41                     Philidor Defense #2    1-0   \n",
      "3      3  2019.04.30  B06                          Modern Defense    0-1   \n",
      "4      4  2019.04.30  B32  Sicilian Defense: Loewenthal Variation    1-0   \n",
      "\n",
      "  Termination TimeControl     UTCDate   UTCTime Move_ply_1  ... Clock_ply_193  \\\n",
      "0      Normal       300+3  2019.04.30  22:00:24         d4  ...           NaN   \n",
      "1      Normal       300+0  2019.04.30  22:00:13         e4  ...           NaN   \n",
      "2      Normal       600+0  2019.04.30  22:00:41         e4  ...           NaN   \n",
      "3      Normal        60+0  2019.04.30  22:00:43         e4  ...           NaN   \n",
      "4      Normal       180+0  2019.04.30  22:00:46         e4  ...           NaN   \n",
      "\n",
      "  Clock_ply_194 Clock_ply_195 Clock_ply_196 Clock_ply_197 Clock_ply_198  \\\n",
      "0           NaN           NaN           NaN           NaN           NaN   \n",
      "1           NaN           NaN           NaN           NaN           NaN   \n",
      "2           NaN           NaN           NaN           NaN           NaN   \n",
      "3           NaN           NaN           NaN           NaN           NaN   \n",
      "4           NaN           NaN           NaN           NaN           NaN   \n",
      "\n",
      "  Clock_ply_199 Clock_ply_200 Category                         mapped_opening  \n",
      "0           NaN           NaN    Blitz  Queen's Pawn Game: Chigorin Variation  \n",
      "1           NaN           NaN    Blitz            Italian Game: Paris Defense  \n",
      "2           NaN           NaN    Rapid                       Philidor Defense  \n",
      "3           NaN           NaN   Bullet                         Modern Defense  \n",
      "4           NaN           NaN    Blitz  Sicilian Defense: Löwenthal Variation  \n",
      "\n",
      "[5 rows x 411 columns]\n"
     ]
    }
   ],
   "source": [
    "# Map the opening names to the game data\n",
    "result_df = mapper.get_opening_name_from_game(game_data)\n",
    "\n",
    "# Add the mapped opening names to the original game data DataFrame\n",
    "game_data['mapped_opening'] = result_df['opening_name']\n",
    "\n",
    "# Display the first 5 rows of the updated game data DataFrame\n",
    "print(f\"First 5 rows with mapped openings: \\n{game_data.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Train/Test Split\n",
    "\n",
    "Here: \n",
    "\n",
    "Split the dataset into training and test sets with a 70/30 ratio. Display the sizes of the train and test datasets to verify the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 140000\n",
      "Testing data size: 60000\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train/Test Split\n",
    "# Split the dataset into training and test sets (70/30)\n",
    "train_df, test_df = train_test_split(game_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the sizes of the train and test datasets\n",
    "print(f\"Training data size: {len(train_df)}\")\n",
    "print(f\"Testing data size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Generate Random Code\n",
    "\n",
    "Here:\n",
    "\n",
    "- Define the number of loss values\n",
    "- Randomly select a number of variables depending on the loss values \n",
    "- Rename the random values as move_ply_xx and then drop \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of training data after random move removal:\n",
      "         Index        Date  ECO  \\\n",
      "21269    21269  2019.05.25  A43   \n",
      "187660  187660  2019.05.20  B32   \n",
      "774        774  2019.05.01  A04   \n",
      "184577  184577  2019.05.20  B30   \n",
      "37127    37127  2019.05.28  D06   \n",
      "\n",
      "                                                  Opening Result Termination  \\\n",
      "21269               Benoni Defense: Benoni-Indian Defense    0-1      Normal   \n",
      "187660             Sicilian Defense: Loewenthal Variation    1-0      Normal   \n",
      "774                Zukertort Opening: Kingside Fianchetto    1-0      Normal   \n",
      "184577                     Sicilian Defense: Old Sicilian    1-0      Normal   \n",
      "37127   Queen's Gambit Refused: Marshall Defense, Tan ...    1-0      Normal   \n",
      "\n",
      "       TimeControl     UTCDate   UTCTime Move_ply_1  ... Clock_ply_195  \\\n",
      "21269       900+15  2019.05.25  20:25:43         d4  ...           NaN   \n",
      "187660       300+3  2019.05.20  21:48:48         e4  ...           NaN   \n",
      "774          300+0  2019.05.01   1:20:20        Nf3  ...           NaN   \n",
      "184577      900+15  2019.05.20  12:46:42         e4  ...           NaN   \n",
      "37127        600+0  2019.05.28  10:16:03         d4  ...           NaN   \n",
      "\n",
      "       Clock_ply_196 Clock_ply_197 Clock_ply_198 Clock_ply_199 Clock_ply_200  \\\n",
      "21269            NaN           NaN           NaN           NaN           NaN   \n",
      "187660           NaN           NaN           NaN           NaN           NaN   \n",
      "774              NaN           NaN           NaN           NaN           NaN   \n",
      "184577           NaN           NaN           NaN           NaN           NaN   \n",
      "37127            NaN           NaN           NaN           NaN           NaN   \n",
      "\n",
      "         Category                                     mapped_opening  \\\n",
      "21269   Classical              Benoni Defense: Benoni-Indian Defense   \n",
      "187660      Blitz              Sicilian Defense: Löwenthal Variation   \n",
      "774         Blitz             Zukertort Opening: Kingside Fianchetto   \n",
      "184577  Classical                     Sicilian Defense: Old Sicilian   \n",
      "37127       Rapid  Queen's Gambit Declined: Marshall Defense, Tan...   \n",
      "\n",
      "                                        predicted_opening match  \n",
      "21269               Benoni Defense: Benoni-Indian Defense  True  \n",
      "187660              Sicilian Defense: Löwenthal Variation  True  \n",
      "774                Zukertort Opening: Kingside Fianchetto  True  \n",
      "184577                     Sicilian Defense: Old Sicilian  True  \n",
      "37127   Queen's Gambit Declined: Marshall Defense, Tan...  True  \n",
      "\n",
      "[5 rows x 413 columns]\n",
      "Sample of testing data after random move removal:\n",
      "         Index        Date  ECO                                 Opening  \\\n",
      "119737  119737  2019.05.11  C10      French Defense: Marshall Variation   \n",
      "72272    72272  2019.05.05  B32  Sicilian Defense: Loewenthal Variation   \n",
      "158154  158154  2019.05.17  B06               Robatsch (Modern) Defense   \n",
      "65426    65426  2019.05.31  B07                         Pirc Defense #2   \n",
      "30074    30074  2019.05.27  C62             Ruy Lopez: Steinitz Defense   \n",
      "\n",
      "       Result Termination TimeControl     UTCDate   UTCTime Move_ply_1  ...  \\\n",
      "119737    1-0      Normal      900+15  2019.05.11  12:22:21         e4  ...   \n",
      "72272     0-1      Normal       600+0  2019.05.05  12:29:00         e4  ...   \n",
      "158154    0-1      Normal       600+0  2019.05.17  12:45:44         d4  ...   \n",
      "65426     1-0      Normal        60+0  2019.05.31  14:41:44         d4  ...   \n",
      "30074     1-0      Normal       600+0  2019.05.27   7:04:26         e4  ...   \n",
      "\n",
      "       Clock_ply_195 Clock_ply_196 Clock_ply_197 Clock_ply_198 Clock_ply_199  \\\n",
      "119737           NaN           NaN           NaN           NaN           NaN   \n",
      "72272            NaN           NaN           NaN           NaN           NaN   \n",
      "158154           NaN           NaN           NaN           NaN           NaN   \n",
      "65426            NaN           NaN           NaN           NaN           NaN   \n",
      "30074            NaN           NaN           NaN           NaN           NaN   \n",
      "\n",
      "       Clock_ply_200   Category                         mapped_opening  \\\n",
      "119737           NaN  Classical      French Defense: Paulsen Variation   \n",
      "72272            NaN      Rapid  Sicilian Defense: Löwenthal Variation   \n",
      "158154           NaN      Rapid      Queen's Pawn Game: Modern Defense   \n",
      "65426            NaN     Bullet                         Indian Defense   \n",
      "30074            NaN      Rapid            Ruy Lopez: Steinitz Defense   \n",
      "\n",
      "                            predicted_opening match  \n",
      "119737      French Defense: Paulsen Variation  True  \n",
      "72272   Sicilian Defense: Löwenthal Variation  True  \n",
      "158154      Queen's Pawn Game: Modern Defense  True  \n",
      "65426                          Indian Defense  True  \n",
      "30074             Ruy Lopez: Steinitz Defense  True  \n",
      "\n",
      "[5 rows x 413 columns]\n",
      "Random moves removed from training data (loss3): [33, 7, 29]\n",
      "Random moves removed from testing data (loss3): [4, 26, 9]\n"
     ]
    }
   ],
   "source": [
    "# Generate Random Code and Apply to Both Datasets\n",
    "def generate_random_move_removal(data, losses=[1, 2, 3, 4, 5, 10, 15, 20, 25, 30]):\n",
    "    loss_dict = {}\n",
    "    modified_datasets = []\n",
    "    \n",
    "    # select a number of variables based on the number of rows lossed, \n",
    "    # between 0 and 36 to determine which rows to randomly drop\n",
    "    #### Note- 36 was determined as the longest opening move in the dataset\n",
    "    for loss in losses:\n",
    "        random_moves = random.sample(range(1, 36), loss)\n",
    "        loss_dict[f'loss{loss}'] = random_moves\n",
    "        \n",
    "        modified_data = data.copy()\n",
    "\n",
    "        # set loop to make selected values from above to None \n",
    "        drop_columns = {f'Move_ply_{i}' for i in random_moves}\n",
    "        for i in drop_columns:\n",
    "            modified_data[i] = None\n",
    "            \n",
    "        modified_datasets.append(modified_data)\n",
    "    \n",
    "    return modified_datasets, loss_dict\n",
    "\n",
    "# Apply random move removal to training and testing datasets for all losses\n",
    "train_datasets, train_loss_dict = generate_random_move_removal(train_df)\n",
    "test_datasets, test_loss_dict = generate_random_move_removal(test_df)\n",
    "\n",
    "print(\"Sample of training data after random move removal:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"Sample of testing data after random move removal:\")\n",
    "print(test_df.head())\n",
    "\n",
    "# test example of the loss 3 rows to remove\n",
    "print(\"Random moves removed from training data (loss3):\", train_loss_dict['loss3'])\n",
    "print(\"Random moves removed from testing data (loss3):\", test_loss_dict['loss3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting loss rows to 1, 2, 3 etc\n",
    "#loss = [1, 2, 3, 4, 5, 10, 15, 20, 25, 30]\n",
    "#index = 0\n",
    "\n",
    "# select a number of variables based on the number of rows lossed, \n",
    "# between 0 and 36 to determine which rows to randomly drop\n",
    "#### Note- 36 was determined as the longest opening move in the dataset\n",
    "#while index < len(loss):\n",
    " #   globals()['loss%s' % loss[index]] = random.sample(range(1, 36), loss[index])\n",
    "  #  index += 1\n",
    "\n",
    "# test example of the loss 3 rows to remove\n",
    "#print(loss3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set loop to make selected values from above to None \n",
    "#drop_columns3 = {f'Move_ply_{i}' for i in loss3}\n",
    "#game_data3 = game_data\n",
    "#for i in drop_columns3:\n",
    "#    game_data3[i] = None\n",
    "\n",
    "# test sample for 3 rows loss \n",
    "#print(game_data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Prepare Data for Testing\n",
    "\n",
    "In this step, game data is processed to create sequences from non-null moves, preparing it for pattern recognition testing. This step ensures each game's moves are consolidated into a format suitable for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data by creating move sequences from non-null moves\n",
    "def prepare_game_data_for_testing(game_data, max_plies=200):\n",
    "    \n",
    "    \"\"\"\n",
    "    Prepare the game data by creating move sequences from non-null moves.\n",
    "    \n",
    "    Args:\n",
    "    - game_data (pd.DataFrame): The DataFrame with chess moves.\n",
    "    - max_plies (int): The maximum number of plies to consider (default is 200).\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with a new column 'move_sequence' containing sequences of moves.\n",
    "    \"\"\"\n",
    "    \n",
    "    move_columns = [f'Move_ply_{i+1}' for i in range(max_plies)]\n",
    "    selected_moves_df = game_data[move_columns].copy()\n",
    "\n",
    "    def create_move_sequence(row):\n",
    "        moves = row.dropna().tolist()  # Drop NaN values and convert to list\n",
    "        return ' '.join(moves)\n",
    "\n",
    "    selected_moves_df['move_sequence'] = selected_moves_df.apply(create_move_sequence, axis=1)\n",
    "    selected_moves_df['mapped_opening'] = game_data['mapped_opening']  # Ensure this column exists\n",
    "    return selected_moves_df\n",
    "\n",
    "# Prepare the incomplete game data for testing\n",
    "# For simplicity, let's use the first modified dataset for further processing\n",
    "processed_train_data_sample = prepare_game_data_for_testing(train_datasets[0])\n",
    "processed_test_data_sample = prepare_game_data_for_testing(test_datasets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Test Pattern Recognition on Incomplete Data\n",
    "\n",
    "In this step, the ChessOpeningMapper is used to predict chess openings from the processed, incomplete data. The predicted openings are then compared with the actual mapped openings to determine the accuracy of the model, assessing its ability to handle missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on incomplete training data: 99.99%\n",
      "Accuracy on incomplete testing data: 88.26%\n"
     ]
    }
   ],
   "source": [
    "# Test pattern recognition on incomplete data\n",
    "def test_pattern_recognition_on_incomplete_data(mapper, incomplete_df, dataset_label):\n",
    "    \n",
    "    \"\"\"\n",
    "    Test the pattern recognition on incomplete data using ChessOpeningMapper.\n",
    "    \n",
    "    Args:\n",
    "    - mapper (ChessOpeningMapper): The ChessOpeningMapper instance for mapping openings.\n",
    "    - incomplete_df (pd.DataFrame): The DataFrame containing incomplete chess move data.\n",
    "    - dataset_label (str): Label to indicate which dataset is being tested (e.g., 'Training' or 'Testing').\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with the original and predicted openings for comparison.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use the mapper to predict openings based on incomplete data\n",
    "    incomplete_results = mapper.get_opening_name_from_game(incomplete_df)\n",
    "    incomplete_df['predicted_opening'] = incomplete_results['opening_name']\n",
    "    \n",
    "    if 'mapped_opening' in incomplete_df.columns:\n",
    "        incomplete_df['match'] = incomplete_df['mapped_opening'] == incomplete_df['predicted_opening']\n",
    "        accuracy = incomplete_df['match'].mean()\n",
    "        print(f'Accuracy on incomplete {dataset_label} data: {accuracy:.2%}')\n",
    "    else:\n",
    "        print(f\"No 'mapped_opening' column found in input {dataset_label} data\")\n",
    "    \n",
    "    return incomplete_df\n",
    "\n",
    "# Instantiate ChessOpeningMapper and load trie\n",
    "mapper = ChessOpeningMapper()\n",
    "opening_moves = mapper.load_openings()\n",
    "mapper.create_trie(opening_moves)\n",
    "\n",
    "# Run the test on both training and testing data\n",
    "train_result_df_test = test_pattern_recognition_on_incomplete_data(mapper, processed_train_data_sample, \"training\")\n",
    "test_result_df_test = test_pattern_recognition_on_incomplete_data(mapper, processed_test_data_sample, \"testing\")\n",
    "\n",
    "\n",
    "# Print results for training data\n",
    "#print(\"\\nTraining Data Results:\")\n",
    "#print(\"-\" * 50)\n",
    "#if 'mapped_opening' in train_result_df.columns and 'match' in train_result_df.columns:\n",
    " #   print(train_result_df[['mapped_opening', 'predicted_opening', 'match']].head())\n",
    "#else:\n",
    "#    print(\"Mapped or Match columns not found in the train result DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on incomplete training (loss1) data: 99.99%\n",
      "Accuracy on incomplete testing (loss1) data: 88.26%\n",
      "Accuracy on incomplete training (loss2) data: 98.07%\n",
      "Accuracy on incomplete testing (loss2) data: 96.78%\n",
      "Accuracy on incomplete training (loss3) data: 87.90%\n",
      "Accuracy on incomplete testing (loss3) data: 49.47%\n",
      "Accuracy on incomplete training (loss4) data: 49.15%\n",
      "Accuracy on incomplete testing (loss4) data: 96.78%\n",
      "Accuracy on incomplete training (loss5) data: 49.15%\n",
      "Accuracy on incomplete testing (loss5) data: 67.46%\n",
      "Accuracy on incomplete training (loss10) data: 8.91%\n",
      "Accuracy on incomplete testing (loss10) data: 8.91%\n",
      "Accuracy on incomplete training (loss15) data: 8.80%\n",
      "Accuracy on incomplete testing (loss15) data: 30.27%\n",
      "Accuracy on incomplete training (loss20) data: 6.39%\n",
      "Accuracy on incomplete testing (loss20) data: 0.00%\n",
      "Accuracy on incomplete training (loss25) data: 8.90%\n",
      "Accuracy on incomplete testing (loss25) data: 0.00%\n",
      "Accuracy on incomplete training (loss30) data: 0.00%\n",
      "Accuracy on incomplete testing (loss30) data: 0.01%\n"
     ]
    }
   ],
   "source": [
    "# Test pattern recognition on all losses for both train and test datasets\n",
    "\n",
    "# Initialise a dictionary to store results for each loss scenario\n",
    "results = {}\n",
    "\n",
    "# Loop through each loss scenario in the training loss dictionary\n",
    "# `train_loss_dict.keys()` contains keys like 'loss1', 'loss2', ..., 'loss30'\n",
    "for idx, loss in enumerate(train_loss_dict.keys()):\n",
    "    \n",
    "    # Prepare the training data by creating sequences of moves for the current loss scenario\n",
    "    # `train_datasets[idx]` contains the modified training dataset for the current loss\n",
    "    processed_train_data = prepare_game_data_for_testing(train_datasets[idx])\n",
    "\n",
    "    # Prepare the testing data by creating sequences of moves for the current loss scenario\n",
    "    # `test_datasets[idx]` contains the modified testing dataset for the current loss\n",
    "    processed_test_data = prepare_game_data_for_testing(test_datasets[idx])\n",
    "    \n",
    "    # Test pattern recognition on the processed training data for the current loss\n",
    "    # This function will predict the openings and compare with actual mapped openings\n",
    "    train_result_df = test_pattern_recognition_on_incomplete_data(mapper, processed_train_data, f\"training ({loss})\")\n",
    "\n",
    "    # Test pattern recognition on the processed testing data for the current loss\n",
    "    test_result_df = test_pattern_recognition_on_incomplete_data(mapper, processed_test_data, f\"testing ({loss})\")\n",
    "    \n",
    "    # Store the result dataframes (train and test) in the results dictionary under the current loss key\n",
    "    results[loss] = {\n",
    "        'train': train_result_df, # Result DataFrame for training data\n",
    "        'test': test_result_df # Result DataFrame for testing data\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
